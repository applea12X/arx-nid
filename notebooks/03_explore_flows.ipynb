{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ec5385",
   "metadata": {},
   "source": [
    "# Network Flow Data Exploration\n",
    "\n",
    "This notebook explores the network flow data extracted from Zeek connection logs.\n",
    "\n",
    "## Objectives\n",
    "1. Load and examine the flow data structure\n",
    "2. Analyze basic traffic statistics\n",
    "3. Explore temporal patterns\n",
    "4. Visualize flow characteristics\n",
    "5. Identify potential anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path('../data')\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "INTERIM_DIR = DATA_DIR / 'interim'\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb50387",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa18cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed flow data\n",
    "flows_file = PROCESSED_DIR / 'flows_v0.parquet'\n",
    "\n",
    "if flows_file.exists():\n",
    "    df = pd.read_parquet(flows_file)\n",
    "    print(f\"✓ Loaded {len(df):,} flow records\")\n",
    "    print(f\"  Columns: {len(df.columns)}\")\n",
    "    print(f\"  Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(f\"❌ Flow data not found at {flows_file}\")\n",
    "    print(\"Run 'python scripts/zeek2parquet.py' first to generate flow data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data structure\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_info = df.isnull().sum()\n",
    "missing_info = missing_info[missing_info > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_info) > 0:\n",
    "    print(\"Missing values:\")\n",
    "    for col, count in missing_info.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {col}: {count:,} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"✓ No missing values found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c545de",
   "metadata": {},
   "source": [
    "## 2. Basic Traffic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda47e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol distribution\n",
    "print(\"Protocol Distribution:\")\n",
    "proto_counts = df['proto'].value_counts()\n",
    "for proto, count in proto_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {proto}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Visualize protocol distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "proto_counts.plot(kind='bar')\n",
    "plt.title('Protocol Distribution')\n",
    "plt.ylabel('Number of Flows')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "proto_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Protocol Distribution (%)')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service analysis (if available)\n",
    "if 'service' in df.columns:\n",
    "    print(\"Top 10 Services:\")\n",
    "    service_counts = df['service'].value_counts().head(10)\n",
    "    for service, count in service_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {service}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Visualize top services\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    service_counts.plot(kind='bar')\n",
    "    plt.title('Top 10 Services')\n",
    "    plt.ylabel('Number of Flows')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8567c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic volume statistics\n",
    "numeric_cols = ['orig_bytes', 'resp_bytes', 'duration']\n",
    "available_cols = [col for col in numeric_cols if col in df.columns]\n",
    "\n",
    "if available_cols:\n",
    "    print(\"Traffic Volume Statistics:\")\n",
    "    stats = df[available_cols].describe()\n",
    "    print(stats)\n",
    "    \n",
    "    # Create box plots for traffic metrics\n",
    "    fig, axes = plt.subplots(1, len(available_cols), figsize=(15, 5))\n",
    "    if len(available_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(available_cols):\n",
    "        # Use log scale for better visualization\n",
    "        data = df[col][df[col] > 0]  # Remove zeros for log scale\n",
    "        axes[i].boxplot(np.log10(data))\n",
    "        axes[i].set_title(f'{col} (log10)')\n",
    "        axes[i].set_ylabel('Log10 Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ffb22",
   "metadata": {},
   "source": [
    "## 3. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp if needed\n",
    "if 'ts' in df.columns:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['ts']):\n",
    "        df['ts'] = pd.to_datetime(df['ts'], unit='s')\n",
    "    \n",
    "    # Time range analysis\n",
    "    time_range = df['ts'].max() - df['ts'].min()\n",
    "    print(f\"Time Range: {time_range}\")\n",
    "    print(f\"Start: {df['ts'].min()}\")\n",
    "    print(f\"End: {df['ts'].max()}\")\n",
    "    print(f\"Total flows: {len(df):,}\")\n",
    "    \n",
    "    # Flows per hour\n",
    "    df['hour'] = df['ts'].dt.hour\n",
    "    hourly_flows = df['hour'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    hourly_flows.plot(kind='bar')\n",
    "    plt.title('Flows by Hour of Day')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Number of Flows')\n",
    "    \n",
    "    # Traffic over time (binned)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    df.set_index('ts').resample('1H').size().plot()\n",
    "    plt.title('Traffic Volume Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Flows per Hour')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50525e44",
   "metadata": {},
   "source": [
    "## 4. Flow Characteristics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17535161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived features for analysis\n",
    "if 'orig_bytes' in df.columns and 'resp_bytes' in df.columns:\n",
    "    df['total_bytes'] = df['orig_bytes'] + df['resp_bytes']\n",
    "    df['flow_ratio'] = df['orig_bytes'] / (df['resp_bytes'] + 1)  # +1 to avoid div by zero\n",
    "    \n",
    "    # Distribution of flow sizes\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    # Log scale histogram of total bytes\n",
    "    total_bytes_nonzero = df['total_bytes'][df['total_bytes'] > 0]\n",
    "    plt.hist(np.log10(total_bytes_nonzero), bins=50, alpha=0.7)\n",
    "    plt.xlabel('Log10(Total Bytes)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Flow Sizes')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    # Flow ratio distribution\n",
    "    plt.hist(np.log10(df['flow_ratio'] + 0.001), bins=50, alpha=0.7)\n",
    "    plt.xlabel('Log10(Orig/Resp Ratio)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Flow Direction Bias')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # Duration distribution\n",
    "    if 'duration' in df.columns:\n",
    "        duration_nonzero = df['duration'][df['duration'] > 0]\n",
    "        plt.hist(np.log10(duration_nonzero), bins=50, alpha=0.7)\n",
    "        plt.xlabel('Log10(Duration in seconds)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Flow Duration Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9992df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top talkers analysis\n",
    "if 'id.orig_h' in df.columns and 'id.resp_h' in df.columns:\n",
    "    print(\"Top Source IPs (by flow count):\")\n",
    "    top_sources = df['id.orig_h'].value_counts().head(10)\n",
    "    for ip, count in top_sources.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {ip}: {count:,} flows ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nTop Destination IPs (by flow count):\")\n",
    "    top_dests = df['id.resp_h'].value_counts().head(10)\n",
    "    for ip, count in top_dests.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {ip}: {count:,} flows ({pct:.1f}%)\")\n",
    "    \n",
    "    # Visualize top talkers\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    top_sources.plot(kind='barh')\n",
    "    plt.title('Top Source IPs')\n",
    "    plt.xlabel('Number of Flows')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    top_dests.plot(kind='barh')\n",
    "    plt.title('Top Destination IPs')\n",
    "    plt.xlabel('Number of Flows')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f093684",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a33dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for potential anomalies\n",
    "print(\"Potential Anomaly Indicators:\")\n",
    "\n",
    "# Large flows\n",
    "if 'total_bytes' in df.columns:\n",
    "    large_flow_threshold = df['total_bytes'].quantile(0.99)\n",
    "    large_flows = df[df['total_bytes'] > large_flow_threshold]\n",
    "    print(f\"\\n1. Large flows (>99th percentile: {large_flow_threshold:,.0f} bytes):\")\n",
    "    print(f\"   Count: {len(large_flows)} ({len(large_flows)/len(df)*100:.2f}%)\")\n",
    "    if len(large_flows) > 0:\n",
    "        print(f\"   Largest: {large_flows['total_bytes'].max():,.0f} bytes\")\n",
    "\n",
    "# Long duration flows\n",
    "if 'duration' in df.columns:\n",
    "    long_duration_threshold = df['duration'].quantile(0.99)\n",
    "    long_flows = df[df['duration'] > long_duration_threshold]\n",
    "    print(f\"\\n2. Long duration flows (>99th percentile: {long_duration_threshold:.2f} seconds):\")\n",
    "    print(f\"   Count: {len(long_flows)} ({len(long_flows)/len(df)*100:.2f}%)\")\n",
    "    if len(long_flows) > 0:\n",
    "        print(f\"   Longest: {long_flows['duration'].max():.2f} seconds\")\n",
    "\n",
    "# Unusual protocols or services\n",
    "if 'proto' in df.columns:\n",
    "    rare_protocols = df['proto'].value_counts()\n",
    "    rare_protocols = rare_protocols[rare_protocols < len(df) * 0.01]  # <1% of traffic\n",
    "    if len(rare_protocols) > 0:\n",
    "        print(f\"\\n3. Rare protocols (<1% of traffic):\")\n",
    "        for proto, count in rare_protocols.items():\n",
    "            print(f\"   {proto}: {count} flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection state analysis (if available)\n",
    "if 'conn_state' in df.columns:\n",
    "    print(\"Connection State Distribution:\")\n",
    "    conn_states = df['conn_state'].value_counts()\n",
    "    for state, count in conn_states.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {state}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Look for unusual connection states\n",
    "    unusual_states = ['REJ', 'RSTO', 'RSTOS0', 'SH', 'SHR']\n",
    "    unusual_count = df[df['conn_state'].isin(unusual_states)].shape[0]\n",
    "    if unusual_count > 0:\n",
    "        print(f\"\\nUnusual connection states: {unusual_count} ({unusual_count/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Visualize connection states\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    conn_states.plot(kind='bar')\n",
    "    plt.title('Connection State Distribution')\n",
    "    plt.ylabel('Number of Flows')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cc14c",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== DATASET SUMMARY ===\")\n",
    "print(f\"Total flows: {len(df):,}\")\n",
    "print(f\"Time span: {df['ts'].max() - df['ts'].min() if 'ts' in df.columns else 'Unknown'}\")\n",
    "print(f\"Unique source IPs: {df['id.orig_h'].nunique() if 'id.orig_h' in df.columns else 'Unknown'}\")\n",
    "print(f\"Unique destination IPs: {df['id.resp_h'].nunique() if 'id.resp_h' in df.columns else 'Unknown'}\")\n",
    "print(f\"Protocols: {list(df['proto'].unique()) if 'proto' in df.columns else 'Unknown'}\")\n",
    "\n",
    "if 'total_bytes' in df.columns:\n",
    "    total_traffic = df['total_bytes'].sum()\n",
    "    print(f\"Total traffic: {total_traffic / (1024**3):.2f} GB\")\n",
    "\n",
    "print(\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Generate rolling statistics features\")\n",
    "print(\"2. Create time-series tensors for deep learning\")\n",
    "print(\"3. Train baseline anomaly detection models\")\n",
    "print(\"4. Evaluate model performance on labeled data\")\n",
    "print(\"5. Deploy for real-time inference\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
